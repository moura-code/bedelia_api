# Organized BedelÃ­as Scraper

This is the refactored and organized version of the BedelÃ­as scraper with clean separation of concerns.

## ğŸ“ Project Structure

```
scraper/
â”œâ”€â”€ __init__.py                 # Package initialization
â”œâ”€â”€ main_organized.py           # New main entry point
â”œâ”€â”€ bedelias_scraper.py         # Main scraper class (composition)
â”‚
â”œâ”€â”€ core/                       # Universal web scraping functionality
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ base_scraper.py         # Base scraper with universal methods
â”‚
â”œâ”€â”€ handlers/                   # Page-specific functionality
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ page_handlers.py        # Page interaction handlers
â”‚   â”œâ”€â”€ pagination_handler.py   # Pagination-specific logic
â”‚   â””â”€â”€ requirements_processor.py # Requirements tree parsing
â”‚
â”œâ”€â”€ models/                     # Data models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ subject.py              # Subject and requirements data models
â”‚
â”œâ”€â”€ config/                     # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ constants.py            # All configuration constants
â”‚
â””â”€â”€ utils/                      # Utility functions
    â”œâ”€â”€ __init__.py
    â””â”€â”€ helpers.py              # Helper functions
```

## ğŸ¯ Key Improvements

### **Separation of Concerns**
- **Universal Functions**: In `core/base_scraper.py` - reusable across any web scraping project
- **Page-Specific Functions**: In `handlers/` - specific to BedelÃ­as website interactions
- **Data Models**: In `models/` - structured data representation
- **Configuration**: In `config/` - centralized constants and settings

### **Clean Architecture**
- **Composition Pattern**: Main scraper inherits from specialized components
- **Single Responsibility**: Each class has one clear purpose
- **Type Safety**: Comprehensive type hints throughout
- **Error Handling**: Proper exception handling with retry mechanisms

### **Better Organization**
- **No More Mixed Code**: Universal and specific functionality clearly separated
- **Centralized Configuration**: All hardcoded values in one place
- **Modular Design**: Easy to test, maintain, and extend
- **Clear Interfaces**: Well-defined contracts between components

## ğŸš€ Usage

### **Using the New Organized Structure:**
```python
from scraper import BedeliasScraper

scraper = BedeliasScraper(
    username="your_username",
    password="your_password",
    browser="firefox",  # or "chrome"
    debug=False
)
scraper.run()
```

### **Running from Command Line:**
```bash
python scraper/main_organized.py
```

## ğŸ“Š Component Breakdown

### **Universal Components (Reusable)**
- `BaseScraper`: Browser management, element interaction, waiting strategies
- `extract_table_info()`: Generic table parsing
- `retry_on_exception()`: Retry mechanism for unreliable operations
- Logging and utility functions

### **BedelÃ­as-Specific Components**
- `PageHandlers`: Login, faculty selection, navigation workflows
- `PaginationHandler`: Page navigation specific to BedelÃ­as UI
- `RequirementsProcessor`: Tree parsing specific to PrimeFaces tree structure
- `BedeliasConfig`: All website-specific constants and selectors

### **Data Models**
- `SubjectInfo`: Structured representation of subject data
- `RequirementNode`: Tree structure for requirements

## ğŸ”§ Migration from Old Structure

The old `main.py` mixed everything together. The new structure separates:

1. **What was universal** â†’ `core/base_scraper.py`
2. **What was page-specific** â†’ `handlers/*.py`  
3. **What was configuration** â†’ `config/constants.py`
4. **What was data** â†’ `models/*.py`

This makes the code:
- âœ… Easier to maintain
- âœ… More testable
- âœ… Better documented
- âœ… Cleaner to extend
- âœ… Properly organized

## ğŸ§ª Testing

Each component can now be tested independently:
- Mock the `BaseScraper` for testing page handlers
- Test `RequirementsProcessor` with sample HTML
- Unit test data models and utilities
- Integration test the full `BedeliasScraper`
